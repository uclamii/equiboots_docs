{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Append the parent directory (root) to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "from eda_toolkit import ensure_directory\n",
    "\n",
    "from tqdm import tqdm\n",
    "from aequitas.audit import Audit\n",
    "\n",
    "from py_scripts.functions import perform_bootstrapped_audit, plot_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.pardir, \"public_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base path\n",
    "base_path = os.path.join(os.pardir)\n",
    "\n",
    "# create image paths\n",
    "image_path_png = os.path.join(base_path, \"images\", \"png_images\")\n",
    "image_path_svg = os.path.join(base_path, \"images\", \"svg_images\")\n",
    "\n",
    "# Use the function to ensure'data' directory exists\n",
    "ensure_directory(image_path_png)\n",
    "ensure_directory(image_path_svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, \"adult_predictions.csv\")).set_index(\"Adult_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()  # inspect first 5 rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Audit Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit = Audit(df=df, score_column=\"predicted\", label_column=\"income\")\n",
    "audit.audit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Disparity DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit.disparity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output disparity dataframe to csv file in data path\n",
    "audit.disparity_df.to_csv(os.path.join(data_path, \"disparity_metrics.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = list(range(2000))\n",
    "n_iterations = 2000  # Number of bootstrapping iterations\n",
    "sample_size = 5000  # Sample size for each iteration\n",
    "\n",
    "stratify_columns = [\"race\"]\n",
    "categorical_columns = [\n",
    "    \"sex\",\n",
    "    \"race\",\n",
    "]\n",
    "score_column = \"predicted\"\n",
    "label_column = \"income\"\n",
    "bootstrap_method = \"stratified\"  # stratify or 'balanced'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Bootstrapped Disparity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = perform_bootstrapped_audit(\n",
    "    df=df,\n",
    "    seeds=seeds,\n",
    "    n_iterations=n_iterations,\n",
    "    sample_size=sample_size,\n",
    "    stratify_columns=stratify_columns,\n",
    "    categorical_columns=categorical_columns,\n",
    "    score_column=score_column,\n",
    "    label_column=label_column,\n",
    "    return_disparity_metrics=True,\n",
    ")\n",
    "\n",
    "# Access the results\n",
    "all_metrics_stratified = results_dict[\"all_metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_cols = [\n",
    "    \"pprev_disparity\",\n",
    "    \"fpr_disparity\",\n",
    "    \"tnr_disparity\",\n",
    "    \"tpr_disparity\",\n",
    "    \"fnr_disparity\",\n",
    "    \"precision_disparity\",\n",
    "]\n",
    "\n",
    "nondisparity_columns = [x.replace(\"_disparity\", \"\") for x in metric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_stratified[\"attribute_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Disparity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\n",
    "    all_metrics_stratified,\n",
    "    categories=\"all\",\n",
    "    metric_cols=metric_cols,\n",
    "    include_legend=True,\n",
    "    save_plots=True,\n",
    "    cmap=\"tab20c\",\n",
    "    image_path_png=\"image_path_png\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equi_venv_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
